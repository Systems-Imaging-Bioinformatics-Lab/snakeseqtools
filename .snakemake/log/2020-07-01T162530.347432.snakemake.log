Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 16
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	2	macs2_no_control
	3

[Wed Jul  1 16:25:30 2020]
rule macs2_no_control:
    input: treatments/GCLM_rep1.pruned.bam
    output: GCLM_rep1_macs2
    log: log/GCLM_rep1.macs2
    jobid: 1
    wildcards: sample=GCLM_rep1


[Wed Jul  1 16:25:30 2020]
rule macs2_no_control:
    input: treatments/GCLM_rep2.pruned.bam
    output: GCLM_rep2_macs2
    log: log/GCLM_rep2.macs2
    jobid: 2
    wildcards: sample=GCLM_rep2

[Wed Jul  1 16:25:31 2020]
Finished job 1.
1 of 3 steps (33%) done
[Wed Jul  1 16:25:31 2020]
Finished job 2.
2 of 3 steps (67%) done

[Wed Jul  1 16:25:31 2020]
localrule all:
    input: GCLM_rep1_macs2, GCLM_rep2_macs2
    jobid: 0

[Wed Jul  1 16:25:31 2020]
Finished job 0.
3 of 3 steps (100%) done
Complete log: /nfs/turbo/umms-ukarvind/tstephie/CBSR/rnaseq/snakeRNAseq/snakeseqtools/.snakemake/log/2020-07-01T162530.347432.snakemake.log
